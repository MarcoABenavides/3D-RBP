{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model combines the CNN with a transformer and includes spatial features of the protein. It also incorporates the protein labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "DEBUG_MODE = False  # Set to False to disable debug messages\n",
    "total_samples = 200000 #set the number of samples you want to test. Total number of samples is 1,079,034\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Output directory for intermediate files\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"Results\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Debugging Utility Function\n",
    "def debug_tensor_shape(tensor, name):\n",
    "    \"\"\"Utility function to debug and print tensor shape.\"\"\"\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"[DEBUG] {name} shape: {tensor.shape}\")\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Helper Functions to Process RNA and Protein Data\n",
    "def save_to_csv(data, filename):\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    if isinstance(data, np.ndarray):\n",
    "        pd.DataFrame(data).to_csv(filepath, index=False, header=False)\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        data.to_csv(filepath, index=False)\n",
    "    print(f\"[INFO] Saved {filename} to {OUTPUT_DIR}\")\n",
    "\n",
    "def load_protein_data(protein_file_path):\n",
    "    protein_data = pd.read_csv(protein_file_path)\n",
    "    protein_label = protein_data[\"Protein_Label\"].iloc[0]\n",
    "    protein_data = protein_data.drop(columns=[\"Protein_Label\"], errors=\"ignore\")\n",
    "    protein_data = protein_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    return protein_data, int(protein_label)\n",
    "\n",
    "def load_rna_data(rna_file_path):\n",
    "    rna_data = pd.read_csv(rna_file_path)\n",
    "    rna_data = rna_data.drop(columns=[\"Sequence_Name\", \"Position\"], errors=\"ignore\")\n",
    "    rna_data = rna_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    num_samples = rna_data.shape[0] // 101\n",
    "    rna_samples = rna_data[:num_samples * 101].reshape(num_samples, 101, -1)\n",
    "    rna_features = rna_samples[:, :, :-1]\n",
    "    rna_binding = rna_samples[:, 0, -1]\n",
    "    return rna_features, rna_binding\n",
    "\n",
    "\n",
    "def process_data(base_folder_path, total_samples):\n",
    "    rna_data_list = []\n",
    "    protein_data_list = []\n",
    "    binding_labels = []\n",
    "    protein_labels = []\n",
    "    rna_folders = []\n",
    "\n",
    "    class_counts = defaultdict(int)\n",
    "    max_per_class = total_samples // 17\n",
    "\n",
    "    for root, _, _ in os.walk(base_folder_path):  # Removed `dirs` and `files`\n",
    "        if \"Protein data\" in root:\n",
    "            protein_folder = root\n",
    "            rna_folder = os.path.dirname(protein_folder)\n",
    "\n",
    "            protein_file = glob.glob(os.path.join(protein_folder, \"*_Concatenated_Encoding_Matrix.csv\"))\n",
    "            if not protein_file:\n",
    "                continue\n",
    "            protein_file = protein_file[0]\n",
    "\n",
    "            rna_file = os.path.join(rna_folder, \"RNA_sequences_combined_stacked.csv\")\n",
    "            if not os.path.exists(rna_file):\n",
    "                continue\n",
    "\n",
    "            protein_data, protein_label = load_protein_data(protein_file)\n",
    "            rna_data, rna_binding = load_rna_data(rna_file)\n",
    "\n",
    "            protein_label -= 1\n",
    "            if class_counts[protein_label] >= max_per_class:\n",
    "                continue\n",
    "\n",
    "            sample_size = min(len(rna_data), max_per_class - class_counts[protein_label])\n",
    "            selected_indices = random.sample(range(len(rna_data)), sample_size)\n",
    "            rna_data_sample = rna_data[selected_indices]\n",
    "\n",
    "            for rna in rna_data_sample:  # Removed unused `binding`\n",
    "                if class_counts[protein_label] >= max_per_class:\n",
    "                    break\n",
    "                rna_data_list.append(rna)\n",
    "                protein_data_list.append(np.expand_dims(protein_data, axis=0))\n",
    "                binding_labels.append(1)  # Assumes binding values are all 1; adjust as needed.\n",
    "                protein_labels.append(protein_label)\n",
    "                rna_folders.append(rna_folder)\n",
    "                class_counts[protein_label] += 1\n",
    "\n",
    "    if not rna_data_list or not protein_data_list:\n",
    "        raise ValueError(\"[ERROR] No RNA or Protein data was successfully loaded.\")\n",
    "\n",
    "    rna_data_array = np.array(rna_data_list, dtype=np.float32)\n",
    "    protein_data_array = np.concatenate(protein_data_list, axis=0)\n",
    "    binding_labels_array = np.array(binding_labels, dtype=np.float32)\n",
    "    protein_labels_array = tf.keras.utils.to_categorical(protein_labels, num_classes=17)\n",
    "\n",
    "    return rna_data_array, protein_data_array, binding_labels_array, protein_labels_array, rna_folders\n",
    "\n",
    "# Model Creation\n",
    "def create_hybrid_model(rna_input_shape, protein_input_shape):\n",
    "    # RNA Feature Extraction\n",
    "    rna_input = layers.Input(shape=(101, 8), name=\"RNA_Input\")\n",
    "    print(f\"[DEBUG] Initial RNA Input Shape: {rna_input.shape}\")\n",
    "    x_rna = layers.Conv1D(64, 3, activation=\"relu\")(rna_input)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Conv1D(128, 3, activation=\"relu\")(x_rna)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Flatten()(x_rna)\n",
    "\n",
    "    # Protein Feature Extraction\n",
    "    protein_input = layers.Input(shape=(1003, 27), name=\"Protein_Input\")\n",
    "    print(f\"[DEBUG] Initial Protein Input Shape: {protein_input.shape}\")\n",
    "    x_protein = layers.Conv1D(64, 3, activation=\"relu\")(protein_input)\n",
    "    x_protein = layers.MaxPooling1D(5)(x_protein)\n",
    "    x_protein = layers.Conv1D(128, 3, activation=\"relu\")(x_protein)\n",
    "    x_protein = layers.MaxPooling1D(2)(x_protein)\n",
    "    x_protein = layers.Flatten()(x_protein)\n",
    "\n",
    "    # Combine Features\n",
    "    combined = layers.Concatenate()([x_rna, x_protein])\n",
    "    debug_tensor_shape(combined, \"Combined Features for Transformer\")\n",
    "    combined = layers.Reshape((1, combined.shape[-1]))(combined)\n",
    "    debug_tensor_shape(combined, \"Reshaped Combined Features for Transformer\")\n",
    "    combined = layers.MultiHeadAttention(num_heads=4, key_dim=64)(combined, combined)\n",
    "    debug_tensor_shape(combined, \"Transformer Output\")\n",
    "    combined = layers.GlobalAveragePooling1D()(combined)\n",
    "    debug_tensor_shape(combined, \"Global Pooled Features\")\n",
    "\n",
    "    # Separate Path for Binding Prediction\n",
    "    binding_path = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    debug_tensor_shape(binding_path, \"binding path output\")\n",
    "    binding_output = layers.Dense(1, activation=\"sigmoid\", name=\"Binding_Prediction\")(binding_path)\n",
    "\n",
    "    # Separate Path for Protein Prediction\n",
    "    protein_path = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    debug_tensor_shape(protein_path, \"Protein path output\")\n",
    "    protein_output = layers.Dense(17, activation=\"softmax\", name=\"Protein_Prediction\")(protein_path)\n",
    "\n",
    "    # Model\n",
    "    model = models.Model(inputs=[rna_input, protein_input], outputs=[binding_output, protein_output])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\n",
    "            \"Binding_Prediction\": \"binary_crossentropy\",\n",
    "            \"Protein_Prediction\": \"categorical_crossentropy\",\n",
    "        },\n",
    "        metrics={\n",
    "            \"Binding_Prediction\": \"accuracy\",\n",
    "            \"Protein_Prediction\": \"accuracy\",\n",
    "        },\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    script_dir = os.getcwd()\n",
    "    base_folder_path = os.path.join(script_dir, \"Data\", \"datasets\", \"clip\")\n",
    "\n",
    "    rna_data, protein_data, binding_labels, protein_labels, rna_folders = process_data(base_folder_path, total_samples)\n",
    "    indices = np.arange(len(rna_data))\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=0.2, stratify=protein_labels.argmax(axis=1), random_state=42\n",
    "    )\n",
    "    rna_train, rna_test = rna_data[train_indices], rna_data[test_indices]\n",
    "    protein_train, protein_test = protein_data[train_indices], protein_data[test_indices]\n",
    "    binding_train, binding_test = binding_labels[train_indices], binding_labels[test_indices]\n",
    "    protein_label_train, protein_label_test = protein_labels[train_indices], protein_labels[test_indices]\n",
    "\n",
    "    rna_input_shape = rna_train.shape[1:]\n",
    "    protein_input_shape = protein_train.shape[1:]\n",
    "    model = create_hybrid_model(rna_input_shape, protein_input_shape)\n",
    "\n",
    "    print(f\"[DEBUG] RNA Train Input Shape: {rna_train.shape}\")\n",
    "    print(f\"[DEBUG] Protein Train Input Shape: {protein_train.shape}\")\n",
    "\n",
    "    # Perform a random split\n",
    "    train_rna, val_rna, train_protein, val_protein, train_binding, val_binding, train_labels, val_labels = train_test_split(\n",
    "        rna_train, protein_train, binding_train, protein_label_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train with manually split validation set\n",
    "    model.fit(\n",
    "        [train_rna, train_protein],\n",
    "        {\"Binding_Prediction\": train_binding, \"Protein_Prediction\": train_labels},\n",
    "        validation_data=([val_rna, val_protein], {\"Binding_Prediction\": val_binding, \"Protein_Prediction\": val_labels}),\n",
    "        epochs=3,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "\n",
    "    binding_predictions = model.predict([rna_test, protein_test])[0]  # Binding predictions\n",
    "    protein_predictions = model.predict([rna_test, protein_test])[1]  # Protein class likelihoods\n",
    "\n",
    "    # Prepare Metadata for Outputs\n",
    "    rna_folders_test = [rna_folders[i] for i in test_indices]  # Get folder names for test data\n",
    "    rna_numbers_test = np.arange(len(rna_test))  # Generate RNA numbers (you may have a specific mapping)\n",
    "    binding_ground_truth = binding_test  # Ground truth for binding\n",
    "    protein_ground_truth = np.argmax(protein_label_test, axis=1)  # Ground truth protein classes\n",
    "\n",
    "    # Convert Predictions to Required Formats\n",
    "    binding_pred_binary = (binding_predictions > 0.5).astype(int)  # Convert to binary\n",
    "    protein_pred_classes = np.argmax(protein_predictions, axis=1)  # Predicted protein classes\n",
    "\n",
    "    # First File: Core Predictions and Metadata\n",
    "    core_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "        \"Binding_Ground_Truth\": binding_ground_truth,\n",
    "        \"Binding_Prediction\": binding_pred_binary.flatten(),\n",
    "        \"Protein_Ground_Class\": protein_ground_truth,\n",
    "        \"Protein_Predicted_Class\": protein_pred_classes\n",
    "    })\n",
    "    core_output_file = os.path.join(OUTPUT_DIR, \"core_predictions.csv\")\n",
    "    core_output_data.to_csv(core_output_file, index=False)\n",
    "    print(f\"[INFO] Core predictions saved to {core_output_file}\")\n",
    "\n",
    "    # Second File: Protein Likelihoods\n",
    "    likelihood_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "    })\n",
    "\n",
    "    # Add Likelihoods for Each Protein Class\n",
    "    for class_index in range(protein_predictions.shape[1]):  # Loop over all 17 classes\n",
    "        likelihood_output_data[f\"Protein_Class_{class_index}_Likelihood\"] = protein_predictions[:, class_index]\n",
    "\n",
    "    likelihood_output_file = os.path.join(OUTPUT_DIR, \"protein_likelihoods.csv\")\n",
    "    likelihood_output_data.to_csv(likelihood_output_file, index=False)\n",
    "    print(f\"[INFO] Protein likelihoods saved to {likelihood_output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  warnings.warn(\n",
    "2024-11-27 13:46:49.857312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
    "4000/4000 ━━━━━━━━━━━━━━━━━━━━ 177s 44ms/step - Binding_Prediction_accuracy: 0.9996 - Binding_Prediction_loss: 0.0281 - Protein_Prediction_accuracy: 0.0871 - Protein_Prediction_loss: 5.0269 - loss: 5.0549 - val_Binding_Prediction_accuracy: 1.0000 - val_Binding_Prediction_loss: 6.6461e-06 - val_Protein_Prediction_accuracy: 0.5893 - val_Protein_Prediction_loss: 1.3094 - val_loss: 1.3094\n",
    "Epoch 2/3\n",
    "4000/4000 ━━━━━━━━━━━━━━━━━━━━ 170s 43ms/step - Binding_Prediction_accuracy: 0.9998 - Binding_Prediction_loss: 0.3687 - Protein_Prediction_accuracy: 0.0754 - Protein_Prediction_loss: 4.8736 - loss: 5.2423 - val_Binding_Prediction_accuracy: 1.0000 - val_Binding_Prediction_loss: 0.0000e+00 - val_Protein_Prediction_accuracy: 0.0581 - val_Protein_Prediction_loss: 2.8334 - val_loss: 2.8334\n",
    "Epoch 3/3\n",
    "4000/4000 ━━━━━━━━━━━━━━━━━━━━ 174s 43ms/step - Binding_Prediction_accuracy: 1.0000 - Binding_Prediction_loss: 0.0000e+00 - Protein_Prediction_accuracy: 0.0581 - Protein_Prediction_loss: 2.8658 - loss: 2.8658 - val_Binding_Prediction_accuracy: 1.0000 - val_Binding_Prediction_loss: 0.0000e+00 - val_Protein_Prediction_accuracy: 0.0581 - val_Protein_Prediction_loss: 2.8334 - val_loss: 2.8334\n",
    "   1/1250 ━━━━━━━━━━━━━━━━━━━━ 3:37 174ms/step\n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
    "  warnings.warn(\n",
    "1250/1250 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step\n",
    "1250/1250 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step\n",
    "\n",
    "Although the previous model showed high accuracy prediction for both binding (1.0000) and protein prediction (0.7635) on a lower dataset (1,000). It failed to do so for bigger data sets of 100,000 samples as the binding prediction was  for binding prediction and    for protein prediction. This means that the model could be overfitting for the binding prediction and therefore driving the combined loss to increase the protein prediction. In order to improve the prediction for both models a balanced dataset was tested.\n",
    "\n",
    "Additionally, even though the validation accuracy for binding protein was as high as the testing accuracy  (.98 -1.00) the validation accuracy for protein prediction was extrmely low with 0.0581.\n",
    "\n",
    "As the total data set has\n",
    "\n",
    "- **Binding Samples**: 295,375\n",
    "- **Non-Binding Samples**: 783,659\n",
    "\n",
    "The model is biased (overfitting) towards the non-binding samples so by having the same amount of binding samples vs non binding samples we would increase the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with balanced data, head = 4 and no positional emmbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "DEBUG_MODE = False  # Set to False to disable debug messages\n",
    "total_samples = 20000 #set the number of samples you want to test. Total number of samples is 1,079,034\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Output directory for intermediate files\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"Intermediate_steps\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Debugging Utility Function\n",
    "def debug_tensor_shape(tensor, name):\n",
    "    \"\"\"Utility function to debug and print tensor shape.\"\"\"\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"[DEBUG] {name} shape: {tensor.shape}\")\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Helper Functions to Process RNA and Protein Data\n",
    "def save_to_csv(data, filename):\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    if isinstance(data, np.ndarray):\n",
    "        pd.DataFrame(data).to_csv(filepath, index=False, header=False)\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        data.to_csv(filepath, index=False)\n",
    "    print(f\"[INFO] Saved {filename} to {OUTPUT_DIR}\")\n",
    "\n",
    "def load_protein_data(protein_file_path):\n",
    "    protein_data = pd.read_csv(protein_file_path)\n",
    "    protein_label = protein_data[\"Protein_Label\"].iloc[0]\n",
    "    protein_data = protein_data.drop(columns=[\"Protein_Label\"], errors=\"ignore\")\n",
    "    protein_data = protein_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    return protein_data, int(protein_label)\n",
    "\n",
    "def load_rna_data(rna_file_path):\n",
    "    rna_data = pd.read_csv(rna_file_path)\n",
    "    rna_data = rna_data.drop(columns=[\"Sequence_Name\", \"Position\"], errors=\"ignore\")\n",
    "    rna_data = rna_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    num_samples = rna_data.shape[0] // 101\n",
    "    rna_samples = rna_data[:num_samples * 101].reshape(num_samples, 101, -1)\n",
    "    rna_features = rna_samples[:, :, :-1]\n",
    "    rna_binding = rna_samples[:, 0, -1]\n",
    "    return rna_features, rna_binding\n",
    "\n",
    "def process_data(base_folder_path, total_samples):\n",
    "    rna_data_list = []\n",
    "    protein_data_list = []\n",
    "    binding_labels = []\n",
    "    protein_labels = []\n",
    "    rna_folders = []\n",
    "\n",
    "    class_counts = defaultdict(int)\n",
    "    max_per_class = total_samples // 34  # 17 classes × 2 (binding vs non-binding)\n",
    "\n",
    "    for root, _, _ in os.walk(base_folder_path):  # Removed `dirs` and `files`\n",
    "        if \"Protein data\" in root:\n",
    "            protein_folder = root\n",
    "            rna_folder = os.path.dirname(protein_folder)\n",
    "\n",
    "            protein_file = glob.glob(os.path.join(protein_folder, \"*_Concatenated_Encoding_Matrix.csv\"))\n",
    "            if not protein_file:\n",
    "                continue\n",
    "            protein_file = protein_file[0]\n",
    "\n",
    "            rna_file = os.path.join(rna_folder, \"RNA_sequences_combined_stacked.csv\")\n",
    "            if not os.path.exists(rna_file):\n",
    "                continue\n",
    "\n",
    "            protein_data, protein_label = load_protein_data(protein_file)\n",
    "            rna_data, rna_binding = load_rna_data(rna_file)\n",
    "\n",
    "            protein_label -= 1\n",
    "            for i, rna in enumerate(rna_data):\n",
    "                binding_label = rna_binding[i]\n",
    "\n",
    "                # Enforce class balancing\n",
    "                class_key = (protein_label, binding_label)\n",
    "                if class_counts[class_key] >= max_per_class:\n",
    "                    continue\n",
    "\n",
    "                rna_data_list.append(rna)\n",
    "                protein_data_list.append(np.expand_dims(protein_data, axis=0))\n",
    "                binding_labels.append(binding_label)\n",
    "                protein_labels.append(protein_label)\n",
    "                rna_folders.append(rna_folder)\n",
    "                class_counts[class_key] += 1\n",
    "\n",
    "                # Stop if we have enough total samples\n",
    "                if sum(class_counts.values()) >= total_samples:\n",
    "                    break\n",
    "\n",
    "    if not rna_data_list or not protein_data_list:\n",
    "        raise ValueError(\"[ERROR] No RNA or Protein data was successfully loaded.\")\n",
    "\n",
    "    # Convert to arrays\n",
    "    rna_data_array = np.array(rna_data_list, dtype=np.float32)\n",
    "    protein_data_array = np.concatenate(protein_data_list, axis=0)\n",
    "    binding_labels_array = np.array(binding_labels, dtype=np.float32)\n",
    "    protein_labels_array = tf.keras.utils.to_categorical(protein_labels, num_classes=17)\n",
    "\n",
    "    return rna_data_array, protein_data_array, binding_labels_array, protein_labels_array, rna_folders\n",
    "\n",
    "\n",
    "# Model Creation\n",
    "def create_hybrid_model(rna_input_shape, protein_input_shape):\n",
    "    # RNA Feature Extraction\n",
    "    rna_input = layers.Input(shape=(101, 8), name=\"RNA_Input\")\n",
    "    print(f\"[DEBUG] Initial RNA Input Shape: {rna_input.shape}\")\n",
    "    x_rna = layers.Conv1D(64, 3, activation=\"relu\")(rna_input)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Conv1D(128, 3, activation=\"relu\")(x_rna)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Flatten()(x_rna)\n",
    "\n",
    "    # Protein Feature Extraction\n",
    "    protein_input = layers.Input(shape=(1003, 27), name=\"Protein_Input\")\n",
    "    print(f\"[DEBUG] Initial Protein Input Shape: {protein_input.shape}\")\n",
    "    x_protein = layers.Conv1D(64, 3, activation=\"relu\")(protein_input)\n",
    "    x_protein = layers.MaxPooling1D(5)(x_protein)\n",
    "    x_protein = layers.Conv1D(128, 3, activation=\"relu\")(x_protein)\n",
    "    x_protein = layers.MaxPooling1D(2)(x_protein)\n",
    "    x_protein = layers.Flatten()(x_protein)\n",
    "\n",
    "    # Combine Features\n",
    "    combined = layers.Concatenate()([x_rna, x_protein])\n",
    "    debug_tensor_shape(combined, \"Combined Features for Transformer\")\n",
    "    combined = layers.Reshape((1, combined.shape[-1]))(combined)\n",
    "    debug_tensor_shape(combined, \"Reshaped Combined Features for Transformer\")\n",
    "    combined = layers.MultiHeadAttention(num_heads=8, key_dim=64)(combined, combined)\n",
    "    debug_tensor_shape(combined, \"Transformer Output\")\n",
    "    combined = layers.GlobalAveragePooling1D()(combined)\n",
    "    debug_tensor_shape(combined, \"Global Pooled Features\")\n",
    "\n",
    "    # Separate Path for Binding Prediction\n",
    "    binding_path = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    debug_tensor_shape(binding_path, \"binding path output\")\n",
    "    binding_output = layers.Dense(1, activation=\"sigmoid\", name=\"Binding_Prediction\")(binding_path)\n",
    "\n",
    "    # Separate Path for Protein Prediction\n",
    "    protein_path = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    debug_tensor_shape(protein_path, \"Protein path output\")\n",
    "    protein_output = layers.Dense(17, activation=\"softmax\", name=\"Protein_Prediction\")(protein_path)\n",
    "\n",
    "    # Model\n",
    "    model = models.Model(inputs=[rna_input, protein_input], outputs=[binding_output, protein_output])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\n",
    "            \"Binding_Prediction\": \"binary_crossentropy\",\n",
    "            \"Protein_Prediction\": \"categorical_crossentropy\",\n",
    "        },\n",
    "        metrics={\n",
    "            \"Binding_Prediction\": \"accuracy\",\n",
    "            \"Protein_Prediction\": \"accuracy\",\n",
    "        },\n",
    "    )\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths and parameters\n",
    "    script_dir = os.getcwd()\n",
    "    base_folder_path = os.path.join(script_dir, \"Data\", \"datasets\", \"clip\")\n",
    "\n",
    "    # Process the data\n",
    "    rna_data, protein_data, binding_labels, protein_labels, rna_folders = process_data(base_folder_path, total_samples)\n",
    "\n",
    "    # Create indices for splitting\n",
    "    indices = np.arange(len(rna_data))\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=0.2, stratify=protein_labels.argmax(axis=1), random_state=42\n",
    "    )\n",
    "\n",
    "    # Extract training and testing data\n",
    "    rna_train, rna_test = rna_data[train_indices], rna_data[test_indices]\n",
    "    protein_train, protein_test = protein_data[train_indices], protein_data[test_indices]\n",
    "    binding_train, binding_test = binding_labels[train_indices], binding_labels[test_indices]\n",
    "    protein_label_train, protein_label_test = protein_labels[train_indices], protein_labels[test_indices]\n",
    "\n",
    "    # Create stratified train-validation split\n",
    "    combined_keys = [(protein_label_train[i].argmax(), binding_train[i]) for i in range(len(protein_label_train))]\n",
    "\n",
    "    train_sub_indices, val_indices = train_test_split(\n",
    "        train_indices, test_size=0.2, stratify=combined_keys, random_state=42\n",
    "    )\n",
    "\n",
    "    # Prepare training and validation datasets\n",
    "    train_rna, val_rna = rna_data[train_sub_indices], rna_data[val_indices]\n",
    "    train_protein, val_protein = protein_data[train_sub_indices], protein_data[val_indices]\n",
    "    train_binding, val_binding = binding_labels[train_sub_indices], binding_labels[val_indices]\n",
    "    train_labels, val_labels = protein_labels[train_sub_indices], protein_labels[val_indices]\n",
    "\n",
    "    # Model creation\n",
    "    rna_input_shape = train_rna.shape[1:]\n",
    "    protein_input_shape = train_protein.shape[1:]\n",
    "    model = create_hybrid_model(rna_input_shape, protein_input_shape)\n",
    "\n",
    "    # Model training\n",
    "    model.fit(\n",
    "        [train_rna, train_protein],\n",
    "        {\"Binding_Prediction\": train_binding, \"Protein_Prediction\": train_labels},\n",
    "        validation_data=([val_rna, val_protein], {\"Binding_Prediction\": val_binding, \"Protein_Prediction\": val_labels}),\n",
    "        epochs=3,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    # Predictions on the test set\n",
    "    binding_predictions = model.predict([rna_test, protein_test])[0]  # Binding predictions\n",
    "    protein_predictions = model.predict([rna_test, protein_test])[1]  # Protein class likelihoods\n",
    "\n",
    "    # Prepare Metadata for Outputs\n",
    "    rna_folders_test = [rna_folders[i] for i in test_indices]  # Get folder names for test data\n",
    "    rna_numbers_test = np.arange(len(rna_test))  # Generate RNA numbers (you may have a specific mapping)\n",
    "    binding_ground_truth = binding_test  # Ground truth for binding\n",
    "    protein_ground_truth = np.argmax(protein_label_test, axis=1)  # Ground truth protein classes\n",
    "\n",
    "    # Convert Predictions to Required Formats\n",
    "    binding_pred_binary = (binding_predictions > 0.5).astype(int)  # Convert to binary\n",
    "    protein_pred_classes = np.argmax(protein_predictions, axis=1)  # Predicted protein classes\n",
    "\n",
    "    # First File: Core Predictions and Metadata\n",
    "    core_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "        \"Binding_Ground_Truth\": binding_ground_truth,\n",
    "        \"Binding_Prediction\": binding_pred_binary.flatten(),\n",
    "        \"Protein_Ground_Class\": protein_ground_truth,\n",
    "        \"Protein_Predicted_Class\": protein_pred_classes\n",
    "    })\n",
    "    core_output_file = os.path.join(OUTPUT_DIR, \"core_predictions.csv\")\n",
    "    core_output_data.to_csv(core_output_file, index=False)\n",
    "    print(f\"[INFO] Core predictions saved to {core_output_file}\")\n",
    "\n",
    "    # Second File: Protein Likelihoods\n",
    "    likelihood_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "    })\n",
    "\n",
    "    # Add Likelihoods for Each Protein Class\n",
    "    for class_index in range(protein_predictions.shape[1]):  # Loop over all 17 classes\n",
    "        likelihood_output_data[f\"Protein_Class_{class_index}_Likelihood\"] = protein_predictions[:, class_index]\n",
    "\n",
    "    likelihood_output_file = os.path.join(OUTPUT_DIR, \"protein_likelihoods.csv\")\n",
    "    likelihood_output_data.to_csv(likelihood_output_file, index=False)\n",
    "    print(f\"[INFO] Protein likelihoods saved to {likelihood_output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as we balanced the data ,with the same number of epochs (3), we see that in the first epoch the binding prediciton goes down to .55, but the protein prediction accuracy already starts higher than the last protein prediction accuracy from the previous model. This shows that balancing the data can dramatically improve the models learning by decreasing the overfitting. This overfit decrease of the binding prediciton accuracy made the total loss deacrese be simultaneous for both predictions increasing the protein prediction accuracy. Although this affected the binding  prediction accuracy. We also increeased the number of head from 4 to 8 to increase the sequence length it is clustering.\n",
    "\n",
    "[DEBUG] Initial RNA Input Shape: (None, 101, 8)\n",
    "[DEBUG] Initial Protein Input Shape: (None, 1003, 27)\n",
    "Epoch 1/3\n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['RNA_Input', 'Protein_Input']. Received: the structure of inputs=('*', '*')\n",
    "  warnings.warn(\n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
    "  warnings.warn(\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 101s 247ms/step - Binding_Prediction_accuracy: 0.4988 - Binding_Prediction_loss: 39.0924 - Protein_Prediction_accuracy: 0.3088 - Protein_Prediction_loss: 138.2883 - loss: 177.3809 - val_Binding_Prediction_accuracy: 0.5014 - val_Binding_Prediction_loss: 0.7165 - val_Protein_Prediction_accuracy: 0.7058 - val_Protein_Prediction_loss: 0.6788 - val_loss: 1.3953\n",
    "Epoch 2/3\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 96s 240ms/step - Binding_Prediction_accuracy: 0.5030 - Binding_Prediction_loss: 0.7124 - Protein_Prediction_accuracy: 0.7602 - Protein_Prediction_loss: 0.5576 - loss: 1.2700 - val_Binding_Prediction_accuracy: 0.5183 - val_Binding_Prediction_loss: 0.6918 - val_Protein_Prediction_accuracy: 0.9434 - val_Protein_Prediction_loss: 0.2180 - val_loss: 0.9098\n",
    "Epoch 3/3\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 96s 240ms/step - Binding_Prediction_accuracy: 0.5145 - Binding_Prediction_loss: 0.7058 - Protein_Prediction_accuracy: 0.9418 - Protein_Prediction_loss: 0.2183 - loss: 0.9241 - val_Binding_Prediction_accuracy: 0.5339 - val_Binding_Prediction_loss: 0.7032 - val_Protein_Prediction_accuracy: 0.9409 - val_Protein_Prediction_loss: 0.2423 - val_loss: 0.9454\n",
    " 11/125 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step   \n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
    "  warnings.warn(\n",
    "125/125 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step\n",
    "125/125 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
    "[INFO] Core predictions saved to /Users/marcobenavides/repos/ML4FG/3D-RBP/Intermediate_steps/core_predictions.csv\n",
    "[INFO] Protein likelihoods saved to /Users/marcobenavides/repos/ML4FG/3D-RBP/Intermediate_steps/protein_likelihoods.csv\n",
    "\n",
    "Before and testing this same model with the data balanced the outcome was still very low for protein prediction below .2. By impleemnting a higher head to 8 it immediately bumped the results of the protein oprediction acccuarcy to up to .7 but no the binding prediction accuracy went down to .5\n",
    "\n",
    "So i implemented postional embeddings hoping it woul rememebr the order of both sequences which are extremely important. and improve botha accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before but head of 8 and with positional embedding I also moddified the batch size by increasing it to 100 instead of 32 I thought this would help as it would allow for a more representative population because a 32 would "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Initial RNA Input Shape: (None, 101, 8)\n",
      "[DEBUG] Initial Protein Input Shape: (None, 1003, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 17:15:06.632003: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-11-27 17:15:06.632073: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 48.00 GB\n",
      "2024-11-27 17:15:06.632085: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 18.00 GB\n",
      "2024-11-27 17:15:06.632111: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-27 17:15:06.632123: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['RNA_Input', 'Protein_Input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n",
      "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "2024-11-27 17:15:30.549839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 132/1777\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15:49\u001b[0m 3s/step - Binding_Prediction_accuracy: 0.5027 - Binding_Prediction_loss: 67.5589 - Protein_Prediction_accuracy: 0.0568 - Protein_Prediction_loss: 351.0433 - loss: 418.6022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 242\u001b[0m\n\u001b[1;32m    239\u001b[0m model \u001b[38;5;241m=\u001b[39m create_hybrid_model(rna_input_shape, protein_input_shape)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_rna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_protein\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBinding_Prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_binding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProtein_Prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_rna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_protein\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBinding_Prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_binding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProtein_Prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# Predictions on the test set\u001b[39;00m\n\u001b[1;32m    251\u001b[0m binding_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([rna_test, protein_test])[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Binding predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ML4FG/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "DEBUG_MODE = False  # Set to False to disable debug messages\n",
    "total_samples = 280000 #set the number of samples you want to test. Total number of samples is 1,079,034\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Output directory for intermediate files\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), \"Results\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, model_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.model_dim = model_dim\n",
    "        self.positional_encoding = self._generate_positional_encoding()\n",
    "\n",
    "    def _generate_positional_encoding(self):\n",
    "        positions = np.arange(self.sequence_length)[:, np.newaxis]\n",
    "        dimensions = np.arange(self.model_dim)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (dimensions // 2)) / np.float32(self.model_dim))\n",
    "        angle_rads = positions * angle_rates\n",
    "\n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        return tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.positional_encoding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "# Debugging Utility Function\n",
    "def debug_tensor_shape(tensor, name):\n",
    "    \"\"\"Utility function to debug and print tensor shape.\"\"\"\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"[DEBUG] {name} shape: {tensor.shape}\")\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Helper Functions to Process RNA and Protein Data\n",
    "def save_to_csv(data, filename):\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    if isinstance(data, np.ndarray):\n",
    "        pd.DataFrame(data).to_csv(filepath, index=False, header=False)\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        data.to_csv(filepath, index=False)\n",
    "    print(f\"[INFO] Saved {filename} to {OUTPUT_DIR}\")\n",
    "\n",
    "def load_protein_data(protein_file_path):\n",
    "    protein_data = pd.read_csv(protein_file_path)\n",
    "    protein_label = protein_data[\"Protein_Label\"].iloc[0]\n",
    "    protein_data = protein_data.drop(columns=[\"Protein_Label\"], errors=\"ignore\")\n",
    "    protein_data = protein_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    return protein_data, int(protein_label)\n",
    "\n",
    "def load_rna_data(rna_file_path):\n",
    "    rna_data = pd.read_csv(rna_file_path)\n",
    "    rna_data = rna_data.drop(columns=[\"Sequence_Name\", \"Position\"], errors=\"ignore\")\n",
    "    rna_data = rna_data.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=1).values\n",
    "    num_samples = rna_data.shape[0] // 101\n",
    "    rna_samples = rna_data[:num_samples * 101].reshape(num_samples, 101, -1)\n",
    "    rna_features = rna_samples[:, :, :-1]\n",
    "    rna_binding = rna_samples[:, 0, -1]\n",
    "    return rna_features, rna_binding\n",
    "\n",
    "def process_data(base_folder_path, total_samples):\n",
    "    rna_data_list = []\n",
    "    protein_data_list = []\n",
    "    binding_labels = []\n",
    "    protein_labels = []\n",
    "    rna_folders = []\n",
    "\n",
    "    class_counts = defaultdict(int)\n",
    "    max_per_class = total_samples // 34  # 17 classes × 2 (binding vs non-binding)\n",
    "\n",
    "    for root, _, _ in os.walk(base_folder_path):  # Removed `dirs` and `files`\n",
    "        if \"Protein data\" in root:\n",
    "            protein_folder = root\n",
    "            rna_folder = os.path.dirname(protein_folder)\n",
    "\n",
    "            protein_file = glob.glob(os.path.join(protein_folder, \"*_Concatenated_Encoding_Matrix.csv\"))\n",
    "            if not protein_file:\n",
    "                continue\n",
    "            protein_file = protein_file[0]\n",
    "\n",
    "            rna_file = os.path.join(rna_folder, \"RNA_sequences_combined_stacked.csv\")\n",
    "            if not os.path.exists(rna_file):\n",
    "                continue\n",
    "\n",
    "            protein_data, protein_label = load_protein_data(protein_file)\n",
    "            rna_data, rna_binding = load_rna_data(rna_file)\n",
    "\n",
    "            protein_label -= 1\n",
    "            for i, rna in enumerate(rna_data):\n",
    "                binding_label = rna_binding[i]\n",
    "\n",
    "                # Enforce class balancing\n",
    "                class_key = (protein_label, binding_label)\n",
    "                if class_counts[class_key] >= max_per_class:\n",
    "                    continue\n",
    "\n",
    "                rna_data_list.append(rna)\n",
    "                protein_data_list.append(np.expand_dims(protein_data, axis=0))\n",
    "                binding_labels.append(binding_label)\n",
    "                protein_labels.append(protein_label)\n",
    "                rna_folders.append(rna_folder)\n",
    "                class_counts[class_key] += 1\n",
    "\n",
    "                # Stop if we have enough total samples\n",
    "                if sum(class_counts.values()) >= total_samples:\n",
    "                    break\n",
    "\n",
    "    if not rna_data_list or not protein_data_list:\n",
    "        raise ValueError(\"[ERROR] No RNA or Protein data was successfully loaded.\")\n",
    "\n",
    "    # Convert to arrays\n",
    "    rna_data_array = np.array(rna_data_list, dtype=np.float32)\n",
    "    protein_data_array = np.concatenate(protein_data_list, axis=0)\n",
    "    binding_labels_array = np.array(binding_labels, dtype=np.float32)\n",
    "    protein_labels_array = tf.keras.utils.to_categorical(protein_labels, num_classes=17)\n",
    "\n",
    "    return rna_data_array, protein_data_array, binding_labels_array, protein_labels_array, rna_folders\n",
    "\n",
    "\n",
    "\n",
    "def create_hybrid_model(rna_input_shape, protein_input_shape):\n",
    "    # RNA Feature Extraction\n",
    "    rna_input = layers.Input(shape=rna_input_shape, name=\"RNA_Input\")\n",
    "    print(f\"[DEBUG] Initial RNA Input Shape: {rna_input.shape}\")\n",
    "    x_rna = layers.Conv1D(64, 3, activation=\"relu\")(rna_input)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Conv1D(128, 3, activation=\"relu\")(x_rna)\n",
    "    x_rna = layers.MaxPooling1D(2)(x_rna)\n",
    "    x_rna = layers.Flatten()(x_rna)\n",
    "\n",
    "    # Protein Feature Extraction\n",
    "    protein_input = layers.Input(shape=protein_input_shape, name=\"Protein_Input\")\n",
    "    print(f\"[DEBUG] Initial Protein Input Shape: {protein_input.shape}\")\n",
    "    x_protein = layers.Conv1D(64, 3, activation=\"relu\")(protein_input)\n",
    "    x_protein = layers.MaxPooling1D(5)(x_protein)\n",
    "    x_protein = layers.Conv1D(128, 3, activation=\"relu\")(x_protein)\n",
    "    x_protein = layers.MaxPooling1D(2)(x_protein)\n",
    "    x_protein = layers.Flatten()(x_protein)\n",
    "\n",
    "    # Combine Features\n",
    "    combined = layers.Concatenate()([x_rna, x_protein])\n",
    "    debug_tensor_shape(combined, \"Combined Features for Transformer\")\n",
    "    combined = layers.Reshape((1, combined.shape[-1]))(combined)\n",
    "    debug_tensor_shape(combined, \"Reshaped Combined Features for Transformer\")\n",
    "\n",
    "    # Add Positional Encoding\n",
    "    pos_enc_layer = PositionalEncoding(sequence_length=1, model_dim=combined.shape[-1])\n",
    "    combined_with_pos_enc = pos_enc_layer(combined)\n",
    "\n",
    "    # Transformer Block\n",
    "    combined_with_pos_enc = layers.MultiHeadAttention(num_heads=32, key_dim=64)(combined_with_pos_enc, combined_with_pos_enc)\n",
    "    debug_tensor_shape(combined_with_pos_enc, \"Transformer Output\")\n",
    "    combined_with_pos_enc = layers.GlobalAveragePooling1D()(combined_with_pos_enc)\n",
    "    debug_tensor_shape(combined_with_pos_enc, \"Global Pooled Features\")\n",
    "\n",
    "    # Separate Path for Binding Prediction\n",
    "    binding_path = layers.Dense(128, activation=\"relu\")(combined_with_pos_enc)\n",
    "    debug_tensor_shape(binding_path, \"binding path output\")\n",
    "    binding_output = layers.Dense(1, activation=\"sigmoid\", name=\"Binding_Prediction\")(binding_path)\n",
    "\n",
    "    # Separate Path for Protein Prediction\n",
    "    protein_path = layers.Dense(128, activation=\"relu\")(combined_with_pos_enc)\n",
    "    debug_tensor_shape(protein_path, \"Protein path output\")\n",
    "    protein_output = layers.Dense(17, activation=\"softmax\", name=\"Protein_Prediction\")(protein_path)\n",
    "\n",
    "    # Model\n",
    "    model = models.Model(inputs=[rna_input, protein_input], outputs=[binding_output, protein_output])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\n",
    "            \"Binding_Prediction\": \"binary_crossentropy\",\n",
    "            \"Protein_Prediction\": \"categorical_crossentropy\",\n",
    "        },\n",
    "        metrics={\n",
    "            \"Binding_Prediction\": \"accuracy\",\n",
    "            \"Protein_Prediction\": \"accuracy\",\n",
    "        },\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths and parameters\n",
    "    script_dir = os.getcwd()\n",
    "    base_folder_path = os.path.join(script_dir, \"Data\", \"datasets\", \"clip\")\n",
    "\n",
    "    # Process the data\n",
    "    rna_data, protein_data, binding_labels, protein_labels, rna_folders = process_data(base_folder_path, total_samples)\n",
    "\n",
    "    # Create indices for splitting\n",
    "    indices = np.arange(len(rna_data))\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=0.2, stratify=protein_labels.argmax(axis=1), random_state=42\n",
    "    )\n",
    "\n",
    "    # Extract training and testing data\n",
    "    rna_train, rna_test = rna_data[train_indices], rna_data[test_indices]\n",
    "    protein_train, protein_test = protein_data[train_indices], protein_data[test_indices]\n",
    "    binding_train, binding_test = binding_labels[train_indices], binding_labels[test_indices]\n",
    "    protein_label_train, protein_label_test = protein_labels[train_indices], protein_labels[test_indices]\n",
    "\n",
    "    # Create stratified train-validation split\n",
    "    combined_keys = [(protein_label_train[i].argmax(), binding_train[i]) for i in range(len(protein_label_train))]\n",
    "\n",
    "    train_sub_indices, val_indices = train_test_split(\n",
    "        train_indices, test_size=0.2, stratify=combined_keys, random_state=42\n",
    "    )\n",
    "\n",
    "    # Prepare training and validation datasets\n",
    "    train_rna, val_rna = rna_data[train_sub_indices], rna_data[val_indices]\n",
    "    train_protein, val_protein = protein_data[train_sub_indices], protein_data[val_indices]\n",
    "    train_binding, val_binding = binding_labels[train_sub_indices], binding_labels[val_indices]\n",
    "    train_labels, val_labels = protein_labels[train_sub_indices], protein_labels[val_indices]\n",
    "\n",
    "    # Model creation\n",
    "    rna_input_shape = train_rna.shape[1:]\n",
    "    protein_input_shape = train_protein.shape[1:]\n",
    "    model = create_hybrid_model(rna_input_shape, protein_input_shape)\n",
    "\n",
    "    # Model training\n",
    "    model.fit(\n",
    "        [train_rna, train_protein],\n",
    "        {\"Binding_Prediction\": train_binding, \"Protein_Prediction\": train_labels},\n",
    "        validation_data=([val_rna, val_protein], {\"Binding_Prediction\": val_binding, \"Protein_Prediction\": val_labels}),\n",
    "        epochs=10,\n",
    "        batch_size= 100\n",
    "    )\n",
    "\n",
    "    # Predictions on the test set\n",
    "    binding_predictions = model.predict([rna_test, protein_test])[0]  # Binding predictions\n",
    "    protein_predictions = model.predict([rna_test, protein_test])[1]  # Protein class likelihoods\n",
    "\n",
    "    # Prepare Metadata for Outputs\n",
    "    rna_folders_test = [rna_folders[i] for i in test_indices]  # Get folder names for test data\n",
    "    rna_numbers_test = np.arange(len(rna_test))  # Generate RNA numbers (you may have a specific mapping)\n",
    "    binding_ground_truth = binding_test  # Ground truth for binding\n",
    "    protein_ground_truth = np.argmax(protein_label_test, axis=1)  # Ground truth protein classes\n",
    "\n",
    "    # Convert Predictions to Required Formats\n",
    "    binding_pred_binary = (binding_predictions > 0.5).astype(int)  # Convert to binary\n",
    "    protein_pred_classes = np.argmax(protein_predictions, axis=1)  # Predicted protein classes\n",
    "\n",
    "    # First File: Core Predictions and Metadata\n",
    "    core_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "        \"Binding_Ground_Truth\": binding_ground_truth,\n",
    "        \"Binding_Prediction\": binding_pred_binary.flatten(),\n",
    "        \"Protein_Ground_Class\": protein_ground_truth,\n",
    "        \"Protein_Predicted_Class\": protein_pred_classes\n",
    "    })\n",
    "    core_output_file = os.path.join(OUTPUT_DIR, \"core_predictions.csv\")\n",
    "    core_output_data.to_csv(core_output_file, index=False)\n",
    "    print(f\"[INFO] Core predictions saved to {core_output_file}\")\n",
    "\n",
    "    # Second File: Protein Likelihoods\n",
    "    likelihood_output_data = pd.DataFrame({\n",
    "        \"Folder_Name\": rna_folders_test,\n",
    "        \"RNA_Number\": rna_numbers_test,\n",
    "    })\n",
    "\n",
    "    # Add Likelihoods for Each Protein Class\n",
    "    for class_index in range(protein_predictions.shape[1]):  # Loop over all 17 classes\n",
    "        likelihood_output_data[f\"Protein_Class_{class_index}_Likelihood\"] = protein_predictions[:, class_index]\n",
    "\n",
    "    likelihood_output_file = os.path.join(OUTPUT_DIR, \"protein_likelihoods.csv\")\n",
    "    likelihood_output_data.to_csv(likelihood_output_file, index=False)\n",
    "    print(f\"[INFO] Protein likelihoods saved to {likelihood_output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for previous model but with only 20,000 samples:\n",
    "\n",
    "[DEBUG] Initial RNA Input Shape: (None, 101, 8)\n",
    "[DEBUG] Initial Protein Input Shape: (None, 1003, 27)\n",
    "Epoch 1/3\n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['RNA_Input', 'Protein_Input']. Received: the structure of inputs=('*', '*')\n",
    "  warnings.warn(\n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
    "  warnings.warn(\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 97s 235ms/step - Binding_Prediction_accuracy: 0.4988 - Binding_Prediction_loss: 39.0924 - Protein_Prediction_accuracy: 0.3088 - Protein_Prediction_loss: 138.2883 - loss: 177.3809 - val_Binding_Prediction_accuracy: 0.5014 - val_Binding_Prediction_loss: 0.7165 - val_Protein_Prediction_accuracy: 0.7058 - val_Protein_Prediction_loss: 0.6788 - val_loss: 1.3953\n",
    "Epoch 2/3\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 93s 233ms/step - Binding_Prediction_accuracy: 0.5030 - Binding_Prediction_loss: 0.7124 - Protein_Prediction_accuracy: 0.7602 - Protein_Prediction_loss: 0.5576 - loss: 1.2700 - val_Binding_Prediction_accuracy: 0.5183 - val_Binding_Prediction_loss: 0.6918 - val_Protein_Prediction_accuracy: 0.9434 - val_Protein_Prediction_loss: 0.2180 - val_loss: 0.9098\n",
    "Epoch 3/3\n",
    "400/400 ━━━━━━━━━━━━━━━━━━━━ 92s 229ms/step - Binding_Prediction_accuracy: 0.5145 - Binding_Prediction_loss: 0.7058 - Protein_Prediction_accuracy: 0.9418 - Protein_Prediction_loss: 0.2183 - loss: 0.9241 - val_Binding_Prediction_accuracy: 0.5339 - val_Binding_Prediction_loss: 0.7032 - val_Protein_Prediction_accuracy: 0.9409 - val_Protein_Prediction_loss: 0.2423 - val_loss: 0.9454\n",
    " 14/125 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step   \n",
    "/Users/marcobenavides/miniconda3/envs/ML4FG/lib/python3.9/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
    "  warnings.warn(\n",
    "125/125 ━━━━━━━━━━━━━━━━━━━━ 1s 4ms/step\n",
    "125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step\n",
    "[INFO] Core predictions saved to /Users/marcobenavides/repos/ML4FG/3D-RBP/Intermediate_steps/core_predictions.csv\n",
    "[INFO] Protein likelihoods saved to /Users/marcobenavides/repos/ML4FG/3D-RBP/Intermediate_steps/protein_likelihoods.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4FG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
